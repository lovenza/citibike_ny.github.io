---
title: "Data Wrangling"
author: "Ziang Niu"
date: "2025-11-06"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    theme: cosmo          # Changed from flatly
    css: styles.css       # ADD THIS LINE - links to custom CSS
---
<a href="index.html" class="back-home">
  <i class="fa fa-home"></i> Back to Home
</a>

```{r setup, include=FALSE}
library(tidyverse)
library(janitor)
library(lubridate)
library(geosphere)
library(knitr)

set.seed(235)
```

<div class="hero-section">
  <h1>ðŸ”§ Data Wrangling</h1>
  <p>Transforming Raw Data into Analysis-Ready Insights</p>
</div>

<br>

<div class="info-card">

# Overview

This page documents our comprehensive data wrangling process for the NYC Citi Bike analysis. We transform raw trip data and weather observations into a clean, analysis-ready dataset through:

- **Stratified sampling** to create a manageable 100,000-ride dataset
- **Feature engineering** including geospatial calculations
- **Data integration** merging trip and weather data
- **Categorical variable creation** for meaningful analysis

</div>

<div class="info-card">

# Load and Pre-process Bike Data

Due to the large size of the raw dataset, which exceeds GitHub's storage limits, the file is stored locally. You can access the original data via [https://citibikenyc.com/system-data](https://citibikenyc.com/system-data), where the specific file `202509-citibike-tripdata_3` was selected for this analysis.

This section reads the raw Citibike data from its CSV file, specifying a list of values to interpret as NA. It then performs initial cleaning and feature engineering:

+ Cleans column names to a consistent snake_case format.

+ Parses the started_at and ended_at columns into full datetime objects.

+ Extracts the start_month and start_day for later filtering and grouping.

+ Directly calculates the ride_duration_hours by subtracting the start and end datetimes, which is more efficient and accurate than the original method of converting to strings and back to time objects.

```{r, message=FALSE, warning=FALSE}
file_path <- "raw_data/202509-citibike-tripdata_3.csv"
na_values <- c(".", "NA", "")

bike_data <- read_csv(file_path, na = na_values) %>%
  janitor::clean_names() %>%
  mutate(
    datetime_start_obj = ymd_hms(started_at),
    datetime_end_obj = ymd_hms(ended_at),
    start_month = month(datetime_start_obj),
    start_day = day(datetime_start_obj),
    ride_duration_hours = as.numeric(datetime_end_obj - datetime_start_obj, units = "hours")
  )
```

</div>

<div class="info-card">

# Stratified Daily Sampling

This block creates the smaller sampled_bike_data dataframe (containing 100,000 rides). It first filters the data to include only rides from September. Then, it uses a grouped sampling strategy:

+ It calculates a global sampling rate based on the target size (100,000) and the total rows available in September.

+ `group_by(start_day)` groups the data by the day of the month.

+ `slice_sample(prop = sampling_rate)` applies the sampling rate within each group. This ensures **proportional stratified sampling**, preserving the relative distribution of rides across each day (e.g., busy days remain busy in the sample, quiet days remain quiet).

+ Finally, `ungroup()` removes the grouping structure for subsequent analysis.

```{r}
target_size <- 100000 
total_rows <- sum(bike_data$start_month == 9)
sampling_rate <- target_size / total_rows

sampled_bike_data <- bike_data %>%
  filter(start_month == 9) %>%
  group_by(start_day) %>%
  slice_sample(prop = sampling_rate) %>%
  ungroup()

sampled_bike_data %>%
  count(start_day, name = "count") %>%
  kable(col.names = c("Day", "Count"))
```

</div>

<div class="info-card">

# Feature Engineering and Weather Data Merge

This section enriches the sampled bike data with new geospatial features and joins it with external weather data. 

+ It first loads the NOAA weather data. 

+ Within the sampled_bike_data, it converts latitude/longitude columns to numeric and prepares coordinate matrices to calculate the Haversine distance (The Haversine distance is a way to calculate the shortest distance between two points on the surface of a sphere, such as the Earth, using their latitude and longitude. It accounts for the Earth's curvature, giving a more accurate distance than simple flat-plane formulas. Unit: kilometers.) and bearing (The bearing represents the direction or angle from one point to another, measured clockwise from true north. For example, a bearing of 90Â° means the destination is directly east of the starting point. Unit: degrees) for each ride. 

+ It creates a start_date column in the bike data and converts the DATE column in the weather data to ensure they are both Date objects, which are used as the join key. 

+ Finally, it performs a left_join and runs clean_names() after the join to standardize the new columns from the weather file (e.g., TMAX, PRCP).

```{r, message=FALSE, warning=FALSE}
noaa_data <- read_csv("data/noaa_central_park_2025.csv")

merged_data <- sampled_bike_data %>%
  mutate(
    start_lng = as.numeric(start_lng),
    start_lat = as.numeric(start_lat),
    end_lng = as.numeric(end_lng),
    end_lat = as.numeric(end_lat)
  ) %>%
  mutate(
    start_coords = cbind(start_lng, start_lat),
    end_coords = cbind(end_lng, end_lat),
    distance_km = distHaversine(start_coords, end_coords) / 1000,
    bearing_degrees = bearing(start_coords, end_coords),
    start_date = as.Date(datetime_start_obj)
  ) %>%
  select(-start_coords, -end_coords)

noaa_data_clean <- noaa_data %>%
  mutate(
    DATE = as.Date(DATE)
  )

merged_data <- left_join(merged_data, noaa_data_clean, by = c("start_date" = "DATE")) %>%
  janitor::clean_names()
```

</div>

<div class="info-card">

# Final Categorization and Export

This final block creates categorical variables based on the merged weather data, selects the final columns for the analysis, and exports the result to a new CSV file. 

+ `case_when()` is used to create four new categorical columns:

  - **temp_diff_category**: Based on the diurnal temperature range (tmax - tmin).
    - "High" if temperature difference > 15Â°F
    - "Medium" if 8Â°F < difference â‰¤ 15Â°F
    - "Low" if difference â‰¤ 8Â°F

  - **temp_level_category**: Based on the maximum temperature (tmax).
    - "High" if tmax â‰¥ 80Â°F
    - "Low" if tmax < 80Â°F

  - **rain_category**: Based on precipitation amount (prcp, in inches).
    - "No Rain" for exactly 0
    - "Light Rain" for 0 < prcp â‰¤ 0.3
    - "Medium Rain" for 0.3 < prcp â‰¤ 1.0
    - "Heavy Rain" for prcp > 1.0

  - **weekend_and_holiday**: Based on the day of the month (start_day).
    - "weekend and holiday" for Labor Day (Sept 1) and weekends
    - "workday" for all other days

+ `select()` organizes the dataframe, keeping essential ride info and the new weather categories. 

+ The final, processed dataframe is written to `final_bike_weather_categorized.csv`.

```{r}
final_categorized_data <- merged_data %>%
  mutate(
    temp_diff = tmax - tmin,
    
    temp_diff_category = case_when(
      temp_diff > 15 ~ "High",
      temp_diff > 8  ~ "Medium",
      temp_diff <= 8 ~ "Low",
      TRUE           ~ NA_character_
    ),
    
    temp_level_category = case_when(
      tmax >= 80 ~ "High",
      tmax < 80  ~ "Low",
      TRUE       ~ NA_character_
    ),
    
    rain_category = case_when(
      is.na(prcp)             ~ "Missing",
      prcp == 0               ~ "No Rain",
      prcp > 0 & prcp <= 0.3  ~ "Light Rain",
      prcp > 0.3 & prcp <= 1.0 ~ "Medium Rain",
      prcp > 1.0              ~ "Heavy Rain",
      TRUE                    ~ "Other"
    ),
    
    weekend_and_holiday = case_when(
      start_day %in% c(1, 6, 7, 13, 14, 20, 21, 27, 28) ~ "weekend and holiday",
      TRUE ~ "workday"
    )
  ) %>% 
  select(
    ride_id:start_date,
    tmax, tmin, prcp,
    temp_diff_category, temp_level_category, rain_category, weekend_and_holiday
  )

write_csv(final_categorized_data, "data/final_bike_weather_categorized.csv")
```
</div>

<br>

<div class="highlight-box">

### âœ… Data Wrangling Complete!

Our final dataset contains **100,000 strategically sampled rides** from September 2025, enriched with:
- Temporal features (hour, day, weekday/weekend)
- Geospatial metrics (distance, bearing)
- Weather variables (temperature, precipitation)
- Categorical classifications for analysis

**Next Step**: Explore patterns and relationships in our [EDA & Visualization](EDA.html) section!

</div>

<br>

<a href="index.html" class="back-home">
  <i class="fa fa-home"></i> Back to Home
</a>